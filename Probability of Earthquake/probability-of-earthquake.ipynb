{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": " #  <div style=\"text-align: center\">Probability of Earthquake  </div> \n###  <div style=\"text-align: center\">CLEAR DATA. MADE MODEL. </div> \n<img src='http://s8.picofile.com/file/8355280718/pro.png' width=400 height=400>\n<div style=\"text-align:center\"> last update: <b>17/03/2019</b></div>\n\n\n\nYou can Fork code  and  Follow me on:\n\n> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n> ###### [Kaggle](https://www.kaggle.com/mjbahmani/)\n-------------------------------------------------------------------------------------------------------------\n <b> I hope you find this kernel helpful and some <font color='red'>UPVOTES</font> would be very much appreciated.</b>\n    \n -----------"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": " <a id=\"top\"></a> <br>\n## Notebook  Content\n1. [Introduction](#1)\n1. [Load packages](#2)\n    1. [import](21)\n    1. [Setup](22)\n    1. [Version](23)\n1. [Problem Definition](#3)\n    1. [Problem Feature](#31)\n    1. [Aim](#32)\n    1. [Variables](#33)\n    1. [Evaluation](#34)\n1. [Exploratory Data Analysis(EDA)](#4)\n    1. [Data Collection](#41)\n    1. [Visualization](#42)\n    1. [Data Preprocessing](#43)\n1. [Model Development](#5)\n    1. [SVM](#5)\n    1. [LGBM](#5)\n1. [submission](#6)\n1. [References](#7)\n"
    },
    {
      "metadata": {
        "_uuid": "af63d485947264b68c37768c73ffac21bb631c0f"
      },
      "cell_type": "markdown",
      "source": " <a id=\"1\"></a> <br>\n## 1- Introduction\n**Forecasting earthquakes** is one of the most important problems in Earth science. If you agree, the earthquake forecast is likely to be related to the concepts of **probability**. In this kernel, I try to look at the prediction of the earthquake with the **help** of the concepts of **probability** .\n<img src='https://www.preventionweb.net/files/52472_largeImage.jpg' width=600 height=600 >\nFor anyone taking first steps in data science, **Probability** is a must know concept. Concepts of probability theory are the backbone of many important concepts in data science like inferential statistics to Bayesian networks. It would not be wrong to say that the journey of mastering statistics begins with **probability**.\n\nBefore starting, I have to point out that I used the following great kernel:\n[https://www.kaggle.com/inversion/basic-feature-benchmark](https://www.kaggle.com/inversion/basic-feature-benchmark)"
    },
    {
      "metadata": {
        "_uuid": "733f1f0e45933f46a674df4d9ee6561de156d748"
      },
      "cell_type": "markdown",
      "source": " <a id=\"2\"></a> <br>\n ## 2- Load packages\n  <a id=\"21\"></a> <br>\n## 2-1 Import"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "7646c73810d475601436c096d36498cfaa489ec4"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom catboost import CatBoostRegressor,Pool\nimport matplotlib.patches as patch\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import NuSVR\nfrom scipy.stats import norm\nfrom scipy import linalg\nfrom sklearn import svm\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom tqdm import tqdm\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport random\nimport time\nimport glob\nimport sys\nimport os",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ec9e63f88e677ed60bfe5a8de4bb0b2a8be8b00a"
      },
      "cell_type": "markdown",
      "source": " <a id=\"22\"></a> <br>\n##  2-2 Setup"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "16768a965c3ced6a76d33642e11ecae18f5977e8"
      },
      "cell_type": "code",
      "source": "%matplotlib inline\n%precision 4\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\nnp.set_printoptions(suppress=True)\npd.set_option(\"display.precision\", 15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9bcec14c7403174f2a9fdab866ea8248aa76328d"
      },
      "cell_type": "markdown",
      "source": " <a id=\"23\"></a> <br>\n## 2-3 Version\n"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "4644581a5ce6c2c98ec2668a95037742b189c318"
      },
      "cell_type": "code",
      "source": "print('pandas: {}'.format(pd.__version__))\nprint('numpy: {}'.format(np.__version__))\nprint('Python: {}'.format(sys.version))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ccfe7d54dac0cf31125a49b1981d25a69e679db0"
      },
      "cell_type": "markdown",
      "source": "<a id=\"3\"></a> \n<br>\n## 3- Problem Definition\nI think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n\nProblem Definition has four steps that have illustrated in the picture below:\n<img src=\"http://s8.picofile.com/file/8344103134/Problem_Definition2.png\" width=400 height=400>\n\n> <font color='red'>Note</font> : **Current scientific studies related to earthquake forecasting focus on three key points:** \n1. when the event will occur\n1. where it will occur\n1. how large it will be.\n"
    },
    {
      "metadata": {
        "_uuid": "dc84d5445dab932c46e2c5dfe86f2131e98aa0f1"
      },
      "cell_type": "markdown",
      "source": "<a id=\"31\"></a> \n### 3-1 Problem Feature\n\n1.     Train.csv - A single, continuous training segment of experimental data.\n1.     Test - A folder containing many small segments of test data.\n1.     Slample_sumbission.csv - A sample submission file in the correct format.\n"
    },
    {
      "metadata": {
        "_uuid": "449535074de09edf5cdccb5a63539661fff29be6"
      },
      "cell_type": "markdown",
      "source": "<a id=\"32\"></a> \n### 3-2 Aim\nIn this competition, you will address <font color='red'><b>WHEN</b></font> the earthquake will take place."
    },
    {
      "metadata": {
        "_uuid": "184d1004ff1f90fdf9d475cbb37ea94b89dd2567"
      },
      "cell_type": "markdown",
      "source": "<a id=\"33\"></a> \n### 3-3 Variables\n\n1.     acoustic_data - the seismic signal [int16]\n1.     time_to_failure - the time (in seconds) until the next laboratory earthquake [float64]\n1.     seg_id - the test segment ids for which predictions should be made (one prediction per segment)\n"
    },
    {
      "metadata": {
        "_uuid": "81b77e49bae78bad2c31bc2ce101c1fff8296af0"
      },
      "cell_type": "markdown",
      "source": "<a id=\"34\"></a> \n## 3-4 evaluation\nSubmissions are evaluated using the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) between the predicted time remaining before the next lab earthquake and the act remaining time.\n<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/3ef87b78a9af65e308cf4aa9acf6f203efbdeded'>"
    },
    {
      "metadata": {
        "_uuid": "f8a54abda5d2e30c5cdb25c554bef1f8a341482c"
      },
      "cell_type": "markdown",
      "source": "<a id=\"4\"></a> \n## 4- Exploratory Data Analysis(EDA)\n In this section, we'll analysis how to use graphical and numerical techniques to begin uncovering the structure of your data. \n \n* Which variables suggest interesting relationships?\n* Which observations are unusual?\n* Analysis of the features!\nBy the end of the section, you'll be able to answer these questions and more, while generating graphics that are both insightful and beautiful.  then We will review analytical and statistical operations:\n\n*  Data Collection\n*  Visualization\n*  Data Preprocessing\n*  Data Cleaning"
    },
    {
      "metadata": {
        "_uuid": "c90af9d21a49adcbd478c56871149f1282c58b7f"
      },
      "cell_type": "markdown",
      "source": " <a id=\"41\"></a> <br>\n## 4-1 Data Collection"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "1c883e09dbe7e4b4d7caeb2cf380ec0f07209531"
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b43e8d926e4684a198791c5423b4af2846ecd63"
      },
      "cell_type": "code",
      "source": "%%time\ntrain = pd.read_csv('../input/train.csv' , dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "9be60393f64121beb23124bdec3cef638436e788"
      },
      "cell_type": "code",
      "source": "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\nsubmission.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e0c43159a9a35be28414b553146652d9d2769177"
      },
      "cell_type": "markdown",
      "source": "### memory usage: 3.5 GB"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6779991d0364d999aac0125075c288d4715b3029"
      },
      "cell_type": "code",
      "source": "train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ede4714f78cc1687a1c97ff132b34f6856a82927"
      },
      "cell_type": "code",
      "source": "#train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e62c1931fef1dc46e12938d76620dde6cdcb9d60"
      },
      "cell_type": "code",
      "source": "print(\"Train: rows:{} columns:{}\".format(train.shape[0], train.shape[1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "27a4123149135a8288d18f20ae46641edb645a52"
      },
      "cell_type": "markdown",
      "source": "### Wow! so large(rows:629145480 columns:2) for playing with it, let's select just 150000 rows!"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c3a7c2fc166c47227b4f1b2d8e7d76d4530f6b2d"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a5a1a5ff95e179a776eff92f2c7a32d23c759b54"
      },
      "cell_type": "markdown",
      "source": "### There are 2624 files in test.zip."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eec8b5f8eb051a61c9724e38431b536b0fddad4d"
      },
      "cell_type": "code",
      "source": "len(os.listdir(os.path.join('../input/', 'test')))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "85741d0edc4c03112b60230663699d2f4c3fe73d"
      },
      "cell_type": "markdown",
      "source": "Also we have 2624  row same as number of test files, so this clear that we should predict time_to_failure for all of test files."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "218e95fbcf1dbb6d22086933f36e95971ab9273e"
      },
      "cell_type": "code",
      "source": "submission.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c1eddbf9a17cb7b15b342b4d2d48af7f0ac79006"
      },
      "cell_type": "markdown",
      "source": " <a id=\"42\"></a> <br>\n## 4-2 Visualization\nBecause the size of the database is very large, for the visualization section, we only need to select a small subset of the data."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "7427d2d9ce7dff9d63a355631a1718a6fb6c5847"
      },
      "cell_type": "code",
      "source": "# we change the size of Dataset due to play with it (just loaded %0001)\nmini_train= pd.read_csv(\"../input/train.csv\",nrows=150000)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "_uuid": "53df1775b242c8e3374278075809c98dc3b2fb62"
      },
      "cell_type": "code",
      "source": "mini_train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "_uuid": "b0ba2d971f1b000f2ae343dd684e8789b0fcf6cb"
      },
      "cell_type": "code",
      "source": "mini_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "_uuid": "590ed0ff228f6161e42ada37ef2345e71f7f40f5"
      },
      "cell_type": "code",
      "source": "mini_train.isna().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28b7d475d28834f4947d58894b662cd399f31a8a",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "type(mini_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70207522d405040466649db4664f6dc9cb75849f"
      },
      "cell_type": "markdown",
      "source": "<a id=\"421\"></a> \n### 4-2-1 hist"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04c95213d519d272e2ee16d16f873a2f6f22ba78",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "#acoustic_data means signal\nmini_train[\"acoustic_data\"].hist();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed6ad0832110a8c6b1fe8056fa50e7337b408515"
      },
      "cell_type": "markdown",
      "source": "<a id=\"425\"></a> \n### 4-2-5 Time to failure histogram"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "610c55e007fa11a14fdbc90ba93137766bf1a8ab",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "plt.plot(mini_train[\"time_to_failure\"], mini_train[\"acoustic_data\"])\nplt.title(\"time_to_failure histogram\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7c539dd31e2d389813645c30e997f1728e9f926"
      },
      "cell_type": "markdown",
      "source": "<a id=\"426\"></a> \n### 4-2-6 Distplot"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd6affcd4ac007edc297dc726b3915112384af35",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "sns.distplot(mini_train[\"acoustic_data\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c36884367038758e75c922e8269fc337285949aa"
      },
      "cell_type": "markdown",
      "source": "<a id=\"427\"></a> \n### 4-2-7 kdeplot"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3c21e9aa2dae18fbb2d949f44a0ed728b987daf",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "sns.kdeplot(mini_train[\"acoustic_data\"] )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a436a7a7f1391cb78ae3cec6c8d5adb42f41bd2"
      },
      "cell_type": "raw",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "8afaaae9f83971dd442a16af434d88318d82c352"
      },
      "cell_type": "markdown",
      "source": " <a id=\"43\"></a> <br>\n## 4-3 Data Preprocessing\n"
    },
    {
      "metadata": {
        "_uuid": "81d42fd41c5f8fd08cbd6304705c4c361fc31118"
      },
      "cell_type": "markdown",
      "source": "Because we have only one feature(**acoustic_data**), and the size of the training set is very large( more that 60000000 rows), it is a good idea to reduce the size of the training set with making new segment  and also to increase the number of attributes by using statistical attributes."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "618fc424689577662c303f1d017737c3db125f18"
      },
      "cell_type": "code",
      "source": "# based on : https://www.kaggle.com/inversion/basic-feature-benchmark\nrows = 150_000\nsegments = int(np.floor(train.shape[0] / rows))\nsegments",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c78c897802f62bc576b20cd2c74938473337cd6"
      },
      "cell_type": "code",
      "source": "X_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n                       columns=['ave', 'std', 'max', 'min'])\ny_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n                       columns=['time_to_failure'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a627284f36e7e11d356a6a3cdef2d8c802a7f600"
      },
      "cell_type": "markdown",
      "source": "### y_train is our target for prediction"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5749b5c7998fa07fdce6f4ba83affa7ccbc44e7"
      },
      "cell_type": "code",
      "source": "y_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a2d5e66ad5e467c20a0baed8bc5a0a526a1066d2"
      },
      "cell_type": "markdown",
      "source": "### our train set with 4 new feature"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "466f2d4cb8e00aeedd2f8d28994986593607757b"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0f0e8d06d8c741a802c5cf667bb459ca1dbdbe31"
      },
      "cell_type": "markdown",
      "source": "> <font color='red'>Note:</font>  \n**tqdm** means \"progress\" in Arabic (taqadum, تقدّم) and is an abbreviation for \"I love you so much\" in Spanish (te quiero demasiado). Instantly make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable), and you're done! [https://tqdm.github.io/](https://tqdm.github.io/)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b57e895eca7bf88073d78492ab7b025f6e1ca89b"
      },
      "cell_type": "code",
      "source": "for segment in tqdm(range(segments)):\n    seg = train.iloc[segment*rows:segment*rows+rows]\n    x = seg['acoustic_data'].values\n    y = seg['time_to_failure'].values[-1]\n    \n    y_train.loc[segment, 'time_to_failure'] = y\n    \n    X_train.loc[segment, 'ave'] = x.mean()\n    X_train.loc[segment, 'std'] = x.std()\n    X_train.loc[segment, 'max'] = x.max()\n    X_train.loc[segment, 'min'] = x.min()\n    X_train.loc[segment, 'min'] = x.sum()\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "_uuid": "1d054476a562f14b8d7e88fd2a8ea3b7b70c371c"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f94f3c248f6cef8c9ff3cf19c929bca5ea10d7ec"
      },
      "cell_type": "code",
      "source": "X_train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "11fdfd9ed7aac1bc4505bccdd30277617e1f4407"
      },
      "cell_type": "markdown",
      "source": "### Cheking missing Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38f377a3b2f5fb67b01747fdc8998b5cd358f5b3"
      },
      "cell_type": "code",
      "source": "def check_missing_data(df):\n    flag=df.isna().sum().any()\n    if flag==True:\n        total = df.isnull().sum()\n        percent = (df.isnull().sum())/(df.isnull().count()*100)\n        output = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n        data_type = []\n        # written by MJ Bahmani\n        for col in df.columns:\n            dtype = str(df[col].dtype)\n            data_type.append(dtype)\n        output['Types'] = data_type\n        return(np.transpose(output))\n    else:\n        return(False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07d6da23ab03c139f821ce3caec73dd2225fd816"
      },
      "cell_type": "code",
      "source": "check_missing_data(train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ecf59b2d75b7c0e2cbe0009e4053a34ceac5e51a"
      },
      "cell_type": "markdown",
      "source": "### Now we must create our X_test for submission"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fbb75698961086aa57e6afba1a66d39af6ce9d67"
      },
      "cell_type": "code",
      "source": "X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5abdf2c564a44baf20bbe47a6dc0eb129730ae6"
      },
      "cell_type": "code",
      "source": "X_test.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c3607ae61dd2ddf021f0378429ae4c8bf216546"
      },
      "cell_type": "code",
      "source": "%%time\nfor seg_id in X_test.index:\n    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n    \n    x = seg['acoustic_data'].values\n    \n    X_test.loc[seg_id, 'ave'] = x.mean()\n    X_test.loc[seg_id, 'std'] = x.std()\n    X_test.loc[seg_id, 'max'] = x.max()\n    X_test.loc[seg_id, 'min'] = x.min()\n    X_test.loc[seg_id, 'min'] = x.sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a914c3345e432141f3c21aa0b92aa7c4421d86c"
      },
      "cell_type": "code",
      "source": "X_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5011ae9b1756b1ac509ac18d68d81f33f3c5f218"
      },
      "cell_type": "markdown",
      "source": "Now we have all of the data frames for applying ML algorithms. just adding some feature scaling."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7fbb5ed09d53b7724db6b772bdd33e775dc0ee2d"
      },
      "cell_type": "code",
      "source": "X=X_train.copy()\ny=y_train.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "88ebce2c42e1897252afb76e985dd11c31fdadea"
      },
      "cell_type": "code",
      "source": "scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c2bdc294ca69903873f205a75722a25a8f15ee46"
      },
      "cell_type": "code",
      "source": "X_test_scaled = scaler.transform(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ff1acc7198b0de21a8a75b1c5bfd79466f353ac5"
      },
      "cell_type": "markdown",
      "source": "<a id=\"5\"></a> <br>\n# 5- Model Development"
    },
    {
      "metadata": {
        "_uuid": "3836aeeba3b5aca98a53e33583f1e59c46db31ea"
      },
      "cell_type": "markdown",
      "source": "<a id=\"51\"></a> <br>\n# 5-1 SVM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8531dbee1c3a9382f05ff595884a56e1886a9fa"
      },
      "cell_type": "code",
      "source": "svm = NuSVR()\nsvm.fit(X_train_scaled, y_train.values.flatten())\ny_pred_svm = svm.predict(X_train_scaled)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d5b7e1ab5e577ab579e144bdce10da1ef23fa1d"
      },
      "cell_type": "code",
      "source": "score = mean_absolute_error(y_train.values.flatten(), y_pred_svm)\nprint(f'Score: {score:0.3f}')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6f9f572ba1cf0c6e00c81020a5747aa03cd66a2f"
      },
      "cell_type": "markdown",
      "source": "<a id=\"52\"></a> <br>\n# 5-2 LGBM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "570ae2130887ae74aab5343dfb8cd938b82f3162"
      },
      "cell_type": "code",
      "source": "folds = KFold(n_splits=5, shuffle=True, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "c32ccbc39541caddb1fc2ebeb23cdfc04618eee0"
      },
      "cell_type": "code",
      "source": "params = {'objective' : \"huber\", \n               'boost':\"gbdt\",\n               'metric':\"mae\",\n               'boost_from_average':\"false\",\n               'num_threads':8,\n               'learning_rate' : 0.01,\n               'num_leaves' : 54,\n               'max_depth':-1,\n               'tree_learner' : \"serial\",\n               'feature_fraction' : 0.05,\n               'bagging_freq' : 5,\n               'bagging_fraction' : 0.4,\n               'min_data_in_leaf' : 80,\n               'min_sum_hessian_in_leaf' : 10.0,\n               'verbosity' : 1}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9025251430b1ada86c51f48f5d15311c97be244"
      },
      "cell_type": "code",
      "source": "for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n    print('Fold', fold_n, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        \n    model = lgb.LGBMRegressor(**params, n_estimators = 50000, n_jobs = -1)\n    model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n                    verbose=10000, early_stopping_rounds=200)\n            \n    y_pred_valid = model.predict(X_valid)\n    y_pred_lgb = model.predict(X_test, num_iteration=model.best_iteration_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "641ab93f5769f4c07e909f929099df0d9c3fde94"
      },
      "cell_type": "markdown",
      "source": "# Catboost "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c4494f1e7938978b3385d20827f428fc2a165c95"
      },
      "cell_type": "code",
      "source": "train_pool = Pool(X,y)\ncat_model = CatBoostRegressor(\n                               iterations=3000,# change 25 to 3000 to get best performance \n                               learning_rate=0.03,\n                               eval_metric='MAE',\n                              )\ncat_model.fit(X,y,silent=True)\ny_pred_cat = cat_model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3da2824e537c35961688902a01600839957b80f8"
      },
      "cell_type": "markdown",
      "source": "<a id=\"6\"></a> <br>\n# 6- submission"
    },
    {
      "metadata": {
        "_uuid": "866e3cae7860dc6b250dae2d7ff356b744c10cdf"
      },
      "cell_type": "markdown",
      "source": "### submission for svm"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb3bedef467c3410b52ba3e44225456c799008ae"
      },
      "cell_type": "code",
      "source": "y_pred_svm= svm.predict(X_test_scaled)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abae1f181e3fafd06cb9e6892bf74807e6d3b9c3"
      },
      "cell_type": "code",
      "source": "submission['time_to_failure'] = y_pred_cat\nsubmission.to_csv('submission_svm.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b40d9bdb9e4cff86c7e4e4ec48fc9ff300f747b3"
      },
      "cell_type": "markdown",
      "source": "### Submission for LGBM"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d515bff6468fbba4af108d17f87614dedc34173"
      },
      "cell_type": "code",
      "source": "submission['time_to_failure'] = y_pred_lgb\nsubmission.to_csv('submission_lgb.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "985787e9ac6b2735485878c0e376595bf15cfe30"
      },
      "cell_type": "markdown",
      "source": "### Submission for Catboost"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51245aa42700796721ef19cc022f2521de6ab89d"
      },
      "cell_type": "code",
      "source": "submission['time_to_failure'] = y_pred_cat\nsubmission.to_csv('submission_cat.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0eb7bd5614b50491012b8c50ba108f640b2e83b3"
      },
      "cell_type": "markdown",
      "source": "<a id=\"61\"></a> <br>\n# 6-1 blending"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d759a6f91a2641a72c027c21478c25742d12a4ce"
      },
      "cell_type": "code",
      "source": "blending = y_pred_svm*0.5 + y_pred_lgb*0.5 \nsubmission['time_to_failure']=blending\nsubmission.to_csv('submission_lgb_svm.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "435fe67f1a833ad62045a29288c440c6952d315c"
      },
      "cell_type": "markdown",
      "source": "you can follow me on:\n> ###### [ GitHub](https://github.com/mjbahmani/)\n> ###### [Kaggle](https://www.kaggle.com/mjbahmani/)\n\n <b>I hope you find this kernel helpful and some <font color='red'>UPVOTES</font> would be very much appreciated.<b/>\n "
    },
    {
      "metadata": {
        "_uuid": "87a2ff7337efe70afed219d3e4df4baf5763524e"
      },
      "cell_type": "markdown",
      "source": "<a id=\"7\"></a> <br>\n# 7-References\n1. [Basic Probability Data Science with examples](https://www.analyticsvidhya.com/blog/2017/02/basic-probability-data-science-with-examples/)\n1. [How to self learn statistics of data science](https://medium.com/ml-research-lab/how-to-self-learn-statistics-of-data-science-c05db1f7cfc3)\n1. [Probability statistics for data science- series](https://towardsdatascience.com/probability-statistics-for-data-science-series-83b94353ca48)\n1. [basic-statistics-in-python-probability](https://www.dataquest.io/blog/basic-statistics-in-python-probability/)\n1. [tutorialspoint](https://www.tutorialspoint.com/python/python_poisson_distribution.htm)\n\n## 7-1 Kaggle Kernels\nIn the end , I want to thank all the kernels I've used in this notebook\n1. [basic-feature-benchmark](https://www.kaggle.com/inversion/basic-feature-benchmark)"
    },
    {
      "metadata": {
        "_uuid": "6ef2c570b8457a851fc753134b587d61a4d9082e"
      },
      "cell_type": "markdown",
      "source": "Go to first step: [Course Home Page](https://www.kaggle.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\nGo to next step : [Titanic](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)\n"
    },
    {
      "metadata": {
        "_uuid": "c1f7f7d015529da63ac495e5c2dcd08dc563e249"
      },
      "cell_type": "markdown",
      "source": "# Not Completed yet!!!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}